<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>不辍弦歌  | Scraping all the texts of Luxun(鲁迅) from the Internet using Python (用Python爬取《鲁迅全集》)</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.58.3" />
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    
    
      <link href="/dist/css/app.d98f2eb6bcd1eaedb7edf166bd16af26.css" rel="stylesheet">
    

    

    
      
    

    
    
    <meta property="og:title" content="Scraping all the texts of Luxun(鲁迅) from the Internet using Python (用Python爬取《鲁迅全集》)" />
<meta property="og:description" content="I want to do some text mining practices on the texts of Luxun(鲁迅), a great Chinese writer. The first step is to get all the texts by Luxun, and I have no time typing all the texts word by word. So I decided to srape the texts from an online source.
Source of the texts The texts of Luxun are scraped from 子夜星网. As it claimed, it contains all the texts in the Complete works of Luxun(鲁迅全集)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ge-chunyu.github.io/posts/2019-10-12-scraping-luxun/" />
<meta property="article:published_time" content="2019-10-12T00:00:00+00:00" />
<meta property="article:modified_time" content="2019-10-12T00:00:00+00:00" />
<meta itemprop="name" content="Scraping all the texts of Luxun(鲁迅) from the Internet using Python (用Python爬取《鲁迅全集》)">
<meta itemprop="description" content="I want to do some text mining practices on the texts of Luxun(鲁迅), a great Chinese writer. The first step is to get all the texts by Luxun, and I have no time typing all the texts word by word. So I decided to srape the texts from an online source.
Source of the texts The texts of Luxun are scraped from 子夜星网. As it claimed, it contains all the texts in the Complete works of Luxun(鲁迅全集).">


<meta itemprop="datePublished" content="2019-10-12T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2019-10-12T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="700">



<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Scraping all the texts of Luxun(鲁迅) from the Internet using Python (用Python爬取《鲁迅全集》)"/>
<meta name="twitter:description" content="I want to do some text mining practices on the texts of Luxun(鲁迅), a great Chinese writer. The first step is to get all the texts by Luxun, and I have no time typing all the texts word by word. So I decided to srape the texts from an online source.
Source of the texts The texts of Luxun are scraped from 子夜星网. As it claimed, it contains all the texts in the Complete works of Luxun(鲁迅全集)."/>

  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="https://ge-chunyu.github.io/" class="f3 fw2 hover-white no-underline white-90 dib">
      不辍弦歌
    </a>
    <div class="flex-l items-center">
      

      
      











    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">

    <header class="mt4 w-100">
      <p class="f6 b helvetica tracked">
          
        POSTS
      </p>
      <h1 class="f1 athelas mb1">Scraping all the texts of Luxun(鲁迅) from the Internet using Python (用Python爬取《鲁迅全集》)</h1>
      
      <p class="tracked">
         By <strong>Chunyu Ge 葛淳宇</strong>
      </p>
      
      
      <time class="f6 mv4 dib tracked" datetime="2019-10-12T00:00:00Z">October 12, 2019</time>
      
      
    </header>

    <section class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l">

<p>I want to do some text mining practices on the texts of <em>Luxun(鲁迅)</em>, a great Chinese writer. The first step is to get all the texts by <em>Luxun</em>, and I have no time typing all the texts word by word. So I decided to srape the texts from an online source.</p>

<h2 id="source-of-the-texts">Source of the texts</h2>

<p>The texts of <em>Luxun</em> are scraped from <a href="http://www.ziyexing.com/">子夜星网</a>. As it claimed, it contains all the texts in the <em>Complete works of Luxun(鲁迅全集)</em>. I checked it, and so it did.</p>

<h2 id="get-the-urls-and-titles-of-all-the-articles">Get the urls and titles of all the articles</h2>

<p>The process starts at getting the contents and the urls of the text of Luxun from the parent url <code>http://www.ziyexing.com/luxun/</code>. To access all the urls, I constructed a regular expression and selected all <code>a</code> nodes that share the pattern.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">homepage_res <span style="color:#f92672">=</span> requests<span style="color:#f92672">.</span>get(<span style="color:#e6db74">&#34;www.ziyexing.com/luxun/&#34;</span>)
homepage_soup <span style="color:#f92672">=</span> BeautifulSoup(res<span style="color:#f92672">.</span>text, <span style="color:#e6db74">&#34;html.parser&#34;</span>)
href_re <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>compile(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#34;luxun_\w+_\w+_\d+.htm&#34;</span>)
hrefs <span style="color:#f92672">=</span> homepage_soup<span style="color:#f92672">.</span>find_all(<span style="color:#e6db74">&#34;a&#34;</span>, {<span style="color:#e6db74">&#34;href&#34;</span>:href_re})</code></pre></div>
<p>It is found that although the regular expression covers most of the patterns, some urls are idiosyncratic and do not conform to the regex. I constructed another regex.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">others_re <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>compile(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#34;(zhunfengyuetan)|(gushixinbian)|(gujixubaji)|(zgxssl)|(luxun_shici)\w+&#34;</span>)
other_hrefs <span style="color:#f92672">=</span> homepage_soup<span style="color:#f92672">.</span>find_all(<span style="color:#e6db74">&#34;a&#34;</span>, {<span style="color:#e6db74">&#34;href&#34;</span>:others_re})</code></pre></div>
<p>It is, of course, idiosyncratic, but effective. To use two regexes, I have got all the urls.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">links <span style="color:#f92672">=</span> [href<span style="color:#f92672">.</span>attrs[<span style="color:#e6db74">&#34;href&#34;</span>] <span style="color:#66d9ef">for</span> href <span style="color:#f92672">in</span> hrefs]
other_links <span style="color:#f92672">=</span> [line<span style="color:#f92672">.</span>attrs[<span style="color:#e6db74">&#34;href&#34;</span>] <span style="color:#66d9ef">for</span> line <span style="color:#f92672">in</span> other_hrefs]</code></pre></div>
<p>The title of each url can also be accessed in the <code>a</code> nodes. It can easily accessed using <code>a.text</code>, yet another problem appeared. The most notorious problem in dealing with non-Latin alphabet languages, especially Chinese, is the problem of encoding. When applying <code>a.text</code>, the characters did not show normally. I am fortunately enough to have recently learnt that the encoding of an <code>html</code> page can be seen from the <code>header</code> of the page. I checked it and found that the page is encoded using <code>gb2312</code>. To make the texts return to normal requires encoding in <code>Latin1</code> and subsequently decoding in <code>gb2312</code>. <code>gbk</code>, as a superset of <code>gb2312</code>, works better in decoding.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">titles <span style="color:#f92672">=</span> [href<span style="color:#f92672">.</span>text<span style="color:#f92672">.</span>encode(<span style="color:#e6db74">&#34;latin1&#34;</span>)<span style="color:#f92672">.</span>decode(<span style="color:#e6db74">&#34;gbk&#34;</span>) <span style="color:#66d9ef">for</span> href <span style="color:#f92672">in</span> hrefs]
other_titles <span style="color:#f92672">=</span> [line<span style="color:#f92672">.</span>text<span style="color:#f92672">.</span>encode(<span style="color:#e6db74">&#34;latin1&#34;</span>)<span style="color:#f92672">.</span>decode(<span style="color:#e6db74">&#34;gbk&#34;</span>) <span style="color:#66d9ef">for</span> line <span style="color:#f92672">in</span> other_hrefs]</code></pre></div>
<p>Have got all the urls and corresponding titles, I can proceed to the next step, to scrape all the articles. A brief inspection of the article page show that all the contents of the article are embedded in the <code>p</code> node with property <code>line-height: 150%</code>. A further inspection of other pages show that the <code>line-height</code> can also be <code>130%</code>. So another regex is needed here.</p>

<pre><code>ps_re = re.compile(r&quot;line-height: 1\d0%&quot;)
</code></pre>

<h2 id="get-the-texts">Get the texts</h2>

<p>Put all the pieces together, I wrote several functions to make the process modular and easy to understand.</p>

<p>The <code>get_soup</code> function accesses the given <code>url</code> and returns the <code>BeautifulSoup</code> object.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_soup</span>(base_url, url):
    res <span style="color:#f92672">=</span> requests<span style="color:#f92672">.</span>get(base_url <span style="color:#f92672">+</span> url)
    soup <span style="color:#f92672">=</span> BeautifulSoup(res<span style="color:#f92672">.</span>text, <span style="color:#e6db74">&#34;html.parser&#34;</span>)
    <span style="color:#66d9ef">return</span> soup</code></pre></div>
<p>The <code>get_ps</code> function accepts the <code>soup</code> object and outputs the <code>p</code> nodes, which contain the texts.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">get_ps</span>(soup):
    ps_re <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>compile(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#34;line-height: 1\d0%&#34;</span>)
    ps <span style="color:#f92672">=</span> soup<span style="color:#f92672">.</span>find_all(<span style="color:#e6db74">&#34;p&#34;</span>, {<span style="color:#e6db74">&#34;style&#34;</span>:ps_re})
    <span style="color:#66d9ef">return</span> ps</code></pre></div>
<p>The <code>clean_text</code> function accepts the <code>p</code> nodes and outputs the cleaned text.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">clean_text</span>(texts):
    texts_decoded <span style="color:#f92672">=</span> [text<span style="color:#f92672">.</span>encode(<span style="color:#e6db74">&#34;latin1&#34;</span>, <span style="color:#e6db74">&#34;ignore&#34;</span>)<span style="color:#f92672">.</span>decode(<span style="color:#e6db74">&#34;gbk&#34;</span>, <span style="color:#e6db74">&#34;ignore&#34;</span>) <span style="color:#66d9ef">for</span> text <span style="color:#f92672">in</span> texts]
    texts_decoded <span style="color:#f92672">=</span> [text<span style="color:#f92672">.</span>strip() <span style="color:#66d9ef">for</span> text <span style="color:#f92672">in</span> texts_decoded]
    cleaned_texts <span style="color:#f92672">=</span> [text <span style="color:#66d9ef">for</span> text <span style="color:#f92672">in</span> texts_decoded <span style="color:#66d9ef">if</span> text <span style="color:#f92672">!=</span> <span style="color:#e6db74">&#34;&#34;</span>]
    <span style="color:#66d9ef">return</span> cleaned_texts</code></pre></div>
<p>The <code>write_text</code> function writes the text data in <code>txt</code> fromat in a file named after the title of the article.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">write_text</span>(clean_text, titles, n):
    <span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">&#34;luxun/&#34;</span> <span style="color:#f92672">+</span> titles[n]<span style="color:#f92672">.</span>strip() <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;.txt&#34;</span>, <span style="color:#e6db74">&#34;w&#34;</span>, encoding<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;utf8&#34;</span>) <span style="color:#66d9ef">as</span> file:
        file<span style="color:#f92672">.</span>write(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span><span style="color:#f92672">.</span>join(clean_text))</code></pre></div>
<p>To wrap all these function together, I wrote a <code>main</code> function which do all these stuff at once.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">main</span>(links, titles):
    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(links)):
        soup <span style="color:#f92672">=</span> get_soup(base_url, links[i])
        ps <span style="color:#f92672">=</span> get_ps(soup)
        texts <span style="color:#f92672">=</span> ps[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>text<span style="color:#f92672">.</span>split(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>)
        cleaned_texts <span style="color:#f92672">=</span> clean_text(texts)
        write_text(cleaned_texts, titles, i)
        time<span style="color:#f92672">.</span>sleep(<span style="color:#ae81ff">3</span>)</code></pre></div>
<p>To avoid too much traffic for the site, I used the <code>time.sleep</code> function to pause for three seconds between urls.</p>

<p>Running the <code>main()</code> function, and I got all the articles posted on <a href="http://www.ziyexing.com/">子夜星网</a> by <em>Luxun</em> in one folder.</p>

<h2 id="key-points"><strong>Key points</strong></h2>

<p>There are some traps in this toy project, some of which are interesting. I list some key points below.</p>

<ul>
<li>Use a regex to capture the pattern of the desired urls;</li>
<li>If a regex can not exhaust the pattern, write another one;</li>
<li>Look for encoding schemes in the <code>header</code> of html files;</li>
<li><code>Latin-1</code> works great for Chinese characters!

<ul>
<li>Use <code>text.encode('latin1').decode('gbk')</code>.</li>
</ul></li>
</ul>
<ul class="pa0">
  
</ul>
<div class="mt6">
      
      
      </div>
    </section>

    <aside class="w-30-l mt6-l"><div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
    <p class="f5 b mb3">What&#39;s in this posts</p>
      <nav id="TableOfContents">
<ul>
<li>
<ul>
<li><a href="#source-of-the-texts">Source of the texts</a></li>
<li><a href="#get-the-urls-and-titles-of-all-the-articles">Get the urls and titles of all the articles</a></li>
<li><a href="#get-the-texts">Get the texts</a></li>
<li><a href="#key-points"><strong>Key points</strong></a></li>
</ul></li>
</ul>
</nav>
  </div>




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://ge-chunyu.github.io/" >
    &copy; 2019 不辍弦歌
  </a>
    <div>










</div>
  </div>
</footer>

    

  <script src="/dist/js/app.3fc0f988d21662902933.js"></script>


  </body>
</html>
